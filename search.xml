<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Big Data Specialization -- Introduction to Big Data</title>
    <url>/2020/06/04/Big%20Data/</url>
    <content><![CDATA[<h3 id="Course-1-Introduction-to-Big-Data"><a href="#Course-1-Introduction-to-Big-Data" class="headerlink" title="Course 1 Introduction to Big Data"></a>Course 1 Introduction to Big Data</h3><h4 id="Week-1"><a href="#Week-1" class="headerlink" title="Week 1"></a>Week 1</h4><ul>
<li><p><strong>In-Situ analytical processing:</strong> Bringing the computation to where data is located.</p>
</li>
<li><p><strong>SCADA(Supervisory Control and Data Acquisition)</strong><br>　　It is a type of industrial control system for remote monitoring and control of industrial processes that exists in the physical world, potentially including multiple sites, many types of sensors.In addition to monitoring and control, SCADA system can be used to define actions for reduced waste and improved efficiency in industrial processes,public or private infrastructure processes,facility processes.</p>
<a id="more"></a>

</li>
</ul>
<h4 id="Week-2"><a href="#Week-2" class="headerlink" title="Week 2"></a>Week 2</h4><h5 id="1-The-Characteristics-of-Big-Data-The-Six-Fundamentals-of-Big-Data"><a href="#1-The-Characteristics-of-Big-Data-The-Six-Fundamentals-of-Big-Data" class="headerlink" title="1. The Characteristics of Big Data: The Six Fundamentals of Big Data"></a><strong>1. The Characteristics of Big Data: The Six Fundamentals of Big Data</strong></h5><ol>
<li><p><strong>Volume:</strong> It’s the dimension of big data related to its size and<br>its exponential growth.</p>
</li>
<li><p><strong>Variety:</strong> refers to the ever-increasing different forms that data can come in such as text, images, voice, and geospatial data.</p>
</li>
<li><p><strong>Velocity:</strong> refers to the increasing speed at which big data is created and the increasing speed at which the data needs to be stored and analyzed.</p>
<ul>
<li><strong>Batch Processing （Slow）:</strong> Collect Data, Clean Data, Feed-In Chunks, Wait, Act. </li>
<li><strong>Real-Time Processing ( Fast):</strong> Instantly Capture Streaming Data, Feed real-time to machines, Process Real-Time, Act.</li>
</ul>
</li>
<li><p><strong>Veracity:</strong> refers to the quality of big data. It sometimes gets referred to as validity or volatility referring to the lifetime of the data.</p>
</li>
<li><p><strong>Valence (connectedness):</strong> The more connected data is, the higher it’s valences</p>
</li>
<li><p><strong>Value:</strong> The ultimate goal of big data is to get value out to the data.</p>
</li>
</ol>
<h5 id="2-Defining-the-Questions-Building-a-big-data-strategy"><a href="#2-Defining-the-Questions-Building-a-big-data-strategy" class="headerlink" title="2. Defining the Questions - Building a big data strategy:"></a><strong>2. Defining the Questions - Building a big data strategy:</strong></h5><p>As a summary, when building a big data strategy,it is important to </p>
<ul>
<li>Integrate big data analytics with business objectives</li>
<li>Communicate goals and provide organizational buy-in (Commitment, Sponsorship, Communication) for analytics projects</li>
<li>Build teams with diverse talents, and establish a teamwork mindset.</li>
<li>Remove barriers to data access and integration</li>
<li>Finally, these activities need to be iterated to respond to new business goals and technological advances</li>
</ul>
<p><strong>Five P’s of Data Science</strong></p>
<p><img src="/images/fivep.png" alt="Hadoop Ecosystem"></p>
<ol>
<li><p><strong>Purpose:</strong> The purpose refers to the challenge or set of challenges defined by your big data strategy. The purpose can be related to a scientific analysis with a hypothesis or a business metric that needs to be analyzed based often on Big Data.</p>
</li>
<li><p><strong>People:</strong> The data scientists are often seen as people who possess skills on a variety of topics including science or business domain knowledge; analysis using statistics, machine learning and mathematical knowledge; data management, programming, and computing. In practice, this is generally a group of researchers comprised of people with complementary skills.</p>
</li>
<li><p><strong>Process:</strong> The process of data science includes techniques for statistics, machine learning, programming, computing, and data management. A process is conceptual in the beginning and defines the course set of steps and how everyone can contribute to it. Note that similar reusable processes can apply to many applications with different purposes when employed within different workflows. Data science workflows combine such steps in executable graphs. We believe that process-oriented thinking is a transformative way of conducting data science to connect people and techniques to applications. Execution of such a data science process requires access to many datasets, Big and small, bringing new opportunities and challenges to Data Science. There are many Data Science steps or tasks, such as Data Collection, Data Cleaning, Data Processing/Analysis, Result Visualization, resulting in a Data Science Workflow. Data Science Processes may need user interaction and other manual operations, or be fully automated. Challenges for the data science process include 1) how to easily integrate all needed tasks to build such a process; 2) how to find the best computing resources and efficiently schedule process executions to the resources based on process definition, parameter settings, and user preferences.</p>
</li>
<li><p><strong>Platforms:</strong> Based on the needs of an application-driven purpose and the amount of data and computing required to perform this application, different computing and data platforms can be used as a part of the data science process. This scalability should be made part of any data science solution architecture.</p>
</li>
<li><p><strong>Programmability:</strong> Capturing a scalable data science process requires aid from programming languages, e.g., R, and patterns, e.g., MapReduce. Tools that provide access to such programming techniques are key to making the data science process programmable on a variety of platforms.</p>
</li>
</ol>
<h5 id="3-The-Process-of-Data-Analysis-Five-steps-activities-of-the-data-science-process"><a href="#3-The-Process-of-Data-Analysis-Five-steps-activities-of-the-data-science-process" class="headerlink" title="3. The Process of Data Analysis - Five steps activities of the data science process:"></a><strong>3. The Process of Data Analysis - Five steps activities of the data science process:</strong></h5><ol>
<li><p><strong>Acquire:</strong> includes anything that makes us retrieve data including; finding, accessing, acquiring, and moving data. It includes identification of and authenticated access to all related data. And transportation of data from sources to distributed files systems</p>
</li>
<li><p><strong>Prepare:</strong> </p>
<ul>
<li><strong>Explorer:</strong> The first step in data preparation involves looking at the data to understand its nature, what it means, its quality, and format.</li>
<li><strong>Pre-processing of data:</strong> Pre-processing includes cleaning data, sub-setting or filtering data, creating data, which programs can read and understand, such as modeling raw data into a more defined data model,or packaging it using a specific data format.</li>
</ul>
</li>
<li><p><strong>Analyze:</strong> Select the analytical technique, build models.</p>
</li>
<li><p><strong>Report:</strong> Communicating results includes evaluation of analytical results. Presenting them in a visual way, creating reports that include an assessment of results with respect to success criteria.</p>
</li>
<li><p><strong>Act:</strong> Reporting insights from analysis and determining actions from insights based on the purpose.</p>
</li>
</ol>
<h4 id="Week-3"><a href="#Week-3" class="headerlink" title="Week 3"></a>Week 3</h4><h5 id="1-Basic-Scalable-Concepts-Scalable-Computing-over-the-Internet"><a href="#1-Basic-Scalable-Concepts-Scalable-Computing-over-the-Internet" class="headerlink" title="1. Basic Scalable Concepts - Scalable Computing over the Internet:"></a><strong>1. Basic Scalable Concepts - Scalable Computing over the Internet:</strong></h5><ul>
<li><strong>Parallel computer:</strong>  a parallel computer is a very large number of single computing nodes with specialized capabilities connected to other networks.</li>
<li><strong>Commodity cluster:</strong> affordable parallel computers with an average number of computing nodes.They are not as powerful as traditional parallel computers and are often built out of less specialized nodes. These types of systems have a higher potential for partial failures. It is this type of distributed computing that pushed for a change towards cost-effective reliable and Fault-tolerant systems for management and analysis of big data</li>
</ul>
<h5 id="2-The-Requirements-For-Big-Data-Programming-Model"><a href="#2-The-Requirements-For-Big-Data-Programming-Model" class="headerlink" title="2. The Requirements For Big Data Programming Model:"></a><strong>2. The Requirements For Big Data Programming Model:</strong></h5><ol>
<li><strong>Support Big Data Operation:</strong><ul>
<li>Split volumes of data</li>
<li>Access data fast</li>
<li>Distribute computations to nodes</li>
</ul>
</li>
<li><strong>Handle Fault tolerance</strong><ul>
<li>Replicate data partition</li>
<li>Recover files when needs</li>
</ul>
</li>
<li><strong>Enable Adding More Racks</strong><ul>
<li>Adding new resources to more or faster data without losing performance (scaling out).</li>
<li>Optimized for specific data types</li>
</ul>
</li>
</ol>
<h5 id="3-Getting-Started-With-Hadoop"><a href="#3-Getting-Started-With-Hadoop" class="headerlink" title="3. Getting Started With Hadoop"></a><strong>3. Getting Started With Hadoop</strong></h5><p><img src="/images/eco.png" alt="Hadoop Ecosystem"></p>
<p><strong>HDFS:</strong> The Hadoop Distributed File System, a storage system for big data.It serves as the foundation for most tools in the <strong>Hadoop ecosystem</strong>.</p>
<p>It provides two capabilities that are essential for managing big data.</p>
<ul>
<li>Scalability to large data sets. </li>
<li>Reliability to cope with hardware failures. By default, HDFS maintains three copies of every block</li>
</ul>
<p><strong>Two key components of HDFS:</strong></p>
<ol>
<li><p><strong>NameNode for Metadata:</strong></p>
<ul>
<li>One namenode per cluster</li>
<li>Coordinator of HDFS cluster</li>
<li>Records the name, location in the directory hierarchy and other metadata</li>
<li>Decides which data nodes to store the contents of the file and remembers this mapping</li>
</ul>
</li>
<li><p><strong>DataNode for block storage</strong></p>
<ul>
<li><strong>Datanode</strong> Runs on each node on the cluster and is responsible for storing the file blocks</li>
<li>listens to commands from the name node for block creation, deletion, and replication. </li>
<li>Replication provides two key capabilities: <ul>
<li>Fault tolerance,  Data locality</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><strong>YARN: The Resource Manager for Hadoop</strong><br>YARN interacts with applications and schedules resources for their use.</p>
<p><strong>Essential Gear in YARN engine:</strong></p>
<ul>
<li><strong>Resource manager:</strong> controls all the resources, and decides who gets what</li>
<li><strong>Application Manager:</strong> It negotiates resource from the Resource Manager and it talks to Node Manager to get its tasks completed</li>
<li><strong>Node Manager:</strong> operates at the machine level and is in charge of a single machine</li>
<li><strong>Container (Machine):</strong> abstract Notions that signifies a resource that is a collection of CPU memory disk network and other resources within the Compute node</li>
</ul>
<p><strong>Mapreduce:</strong> 　　</p>
<p>　　It is a big data programming model that supports all<br>the requirements of big data modeling we mentioned. It can model processing large data, split complications into different parallel tasks and make efficient use of large commodity clusters and distributed file systems.</p>
<ul>
<li>Map: Applys operation to all elements and generates key-values pairs.</li>
<li>Reduce: Summarize operation on elements and construct one output file.</li>
</ul>
<p><strong>MapReduce is bad for:</strong></p>
<ul>
<li>Frequently changing data (slow)</li>
<li>Dependent tasks</li>
<li>Interactive analysis</li>
</ul>
<p><strong>When to reconsider Hadoop:</strong></p>
<ul>
<li><p><strong>Key feature that makes problem Hadoop friendly:</strong></p>
<ul>
<li>Future anticipated data growth</li>
<li>Long term availability of data</li>
<li>Many platforms over single datastore</li>
<li>High Volume, High variety</li>
</ul>
</li>
<li><p><strong>Be careful when:</strong></p>
<ul>
<li>Small dataset</li>
<li>Task Level Parallelism ( Furuethrer analysis for which tool to use in Hadoop ecosystem)</li>
<li>Advanced algorithms (Not all algorithms are scalable in Hadoop, or reducible to one of the programming models supported by YARN</li>
<li>Random Data Access ( you may have to read an entire file just to pick one data entry)</li>
</ul>
</li>
</ul>
<h5 id="4-Cloud-Computing-On-demand-computing-it-enables-us-to-compute-any-time-any-anywhere"><a href="#4-Cloud-Computing-On-demand-computing-it-enables-us-to-compute-any-time-any-anywhere" class="headerlink" title="4. Cloud Computing( On-demand computing: it enables us to compute any time any anywhere)"></a><strong>4. Cloud Computing( On-demand computing: it enables us to compute any time any anywhere)</strong></h5><p><strong>Service Model:</strong></p>
<ul>
<li><p><strong>IaaS:</strong> infrastructure as a service, can be defined as a bare minimum rental service. This is like renting a truck from a company that you can assume has hardware and you do the packing of your furniture, and drive to your new house.</p>
</li>
<li><p><strong>PaaS:</strong> platform as a service,<br>is the model where a user is provided with an entire computing platform.<br>This could include the operating system and programming languages that you need</p>
</li>
<li><p><strong>SaaS:</strong> the software as a service model, is the model<br>in which the cloud service provider takes the responsibilities for the hardware and software environments such as the operating system and the application software</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Online Course</category>
      </categories>
      <tags>
        <tag>Coursera</tag>
        <tag>Big Data</tag>
        <tag>UC San Diego</tag>
      </tags>
  </entry>
  <entry>
    <title>Statistical Learning(Rstudio)1-2</title>
    <url>/2020/07/02/Intro-to-Statistical-Learning/</url>
    <content><![CDATA[<h3 id="Practice-1-Data-Analysis"><a href="#Practice-1-Data-Analysis" class="headerlink" title="Practice 1: Data Analysis"></a>Practice 1: Data Analysis</h3>

	<div class="row">
    <embed src="\me\A1.pdf" width="100%" height="550" type="application/pdf">
	</div>




<a id="more"></a>

<h3 id="Practice-2-logistic-Regression-LDA-QDA-KNN"><a href="#Practice-2-logistic-Regression-LDA-QDA-KNN" class="headerlink" title="Practice 2:logistic Regression,LDA,QDA,KNN"></a>Practice 2:logistic Regression,LDA,QDA,KNN</h3>

	<div class="row">
    <embed src="\me\A2.pdf" width="100%" height="550" type="application/pdf">
	</div>



]]></content>
      <categories>
        <category>Project</category>
      </categories>
      <tags>
        <tag>Rstudio</tag>
        <tag>Data Science</tag>
      </tags>
  </entry>
  <entry>
    <title>Quantitative Finance</title>
    <url>/2020/06/29/Computational-Finance/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>Finance</category>
      </categories>
      <tags>
        <tag>Rstudio</tag>
        <tag>Quant</tag>
      </tags>
  </entry>
  <entry>
    <title>HackerRank 30-days Python</title>
    <url>/2020/06/04/My-second-post-to-test/</url>
    <content><![CDATA[<blockquote>
<p>This post only records the problems I made mistakes.</p>
</blockquote>
<h4 id="Intro-to-Conditional-Statements"><a href="#Intro-to-Conditional-Statements" class="headerlink" title="Intro to Conditional Statements"></a>Intro to Conditional Statements</h4><p><strong>Task:</strong> Given an integer,n, perform the following conditional actions:</p>
<ul>
<li>If  is odd, print Weird</li>
<li>If  is even and in the inclusive range of  to , print Not Weird</li>
<li>If  is even and in the inclusive range of  to , print Weird</li>
<li>If  is even and greater than , print Not Weird</li>
</ul>
<p>Complete the stub code provided in your editor to print whether or not is weird.</p>
<a id="more"></a>

<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">   n = int(input().strip())</span><br><span class="line">   <span class="keyword">if</span> n%<span class="attribute">2</span>==0 <span class="keyword">and</span> (n <span class="keyword">in</span> range (2,6) <span class="keyword">or</span> n&gt;20):</span><br><span class="line">   		<span class="builtin-name">print</span>(<span class="string">'Not Weird'</span>)</span><br><span class="line">   <span class="keyword">if</span> n%<span class="attribute">2</span>==1 <span class="keyword">or</span> (n%<span class="attribute">2</span>==0 <span class="keyword">and</span> (n <span class="keyword">in</span> range(6,21))):</span><br><span class="line">      <span class="builtin-name">print</span>(<span class="string">'Weird'</span>)</span><br></pre></td></tr></table></figure>
<p><strong>Note:</strong> When think about the condition, we can simply catergorize the condition and try whether we can put them in one statement, which will make the codes cleaner.</p>
<h4 id="Class-vs-Instance"><a href="#Class-vs-Instance" class="headerlink" title="Class vs. Instance"></a>Class vs. Instance</h4><p><strong>Task:</strong> Write a Person class with an instance variable,<strong><em>age</em> <em>*,and a constructor that takes an integer,</em></strong>initialAge<strong>* , as a parameter. The constructor must assign *</strong>initialAge<strong>* to <em>age</em> after confirming the argument passed as *</strong>initialAge<strong>* is not negative; if a negative argument is passed as *</strong>initialAge<strong>*, the constructor should set *</strong>age*** to 0 and print Age is not valid, setting age to 0.. In addition, you must write the following instance methods:</p>
<ol>
<li>yearPasses() should increase the instance variable by 1.</li>
<li>amIOld() should perform the following conditional actions:<ul>
<li>If <strong>age &lt; 13</strong> , print You are young..</li>
<li>If <strong>age $\geq$ 13</strong> and <strong>age &lt; 18</strong>, print You are a teenager..</li>
<li>Otherwise, print You are old..</li>
</ul>
</li>
</ol>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">class Person:</span><br><span class="line">    age = 0</span><br><span class="line">    def __init__(self,initialAge):</span><br><span class="line">        # <span class="builtin-name">Add</span> some more code <span class="keyword">to</span> <span class="builtin-name">run</span> some checks on initialAge</span><br><span class="line">        <span class="keyword">if</span> initialAge &lt; 0:</span><br><span class="line">            <span class="builtin-name">print</span> (<span class="string">"Age is not valid, setting age to 0."</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.age = initialAge</span><br><span class="line">    def amIOld(self):</span><br><span class="line">        # <span class="keyword">Do</span> some computations <span class="keyword">in</span> here <span class="keyword">and</span> <span class="builtin-name">print</span> out the correct statement <span class="keyword">to</span> the console</span><br><span class="line">        <span class="keyword">if</span> self.age &lt; 13:</span><br><span class="line">            <span class="builtin-name">print</span> (<span class="string">"You are young."</span>)</span><br><span class="line">        elif self.age &gt;= 13 <span class="keyword">and</span> self.age &lt; 18:</span><br><span class="line">            <span class="builtin-name">print</span> (<span class="string">"You are a teenager."</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="builtin-name">print</span> (<span class="string">"You are old."</span>)</span><br><span class="line">    def yearPasses(self):</span><br><span class="line">        # Increment the age of the person <span class="keyword">in</span> here</span><br><span class="line">        self.age += 1</span><br></pre></td></tr></table></figure>
<h4 id="Loops"><a href="#Loops" class="headerlink" title="Loops"></a>Loops</h4><p><strong>Task</strong>: Given an integer, , print its first  multiples. Each multiple  (where ) should be printed on a new line in the form: n x i = result.</p>
<p><strong>input Format:</strong> A single integer,<strong>n</strong></p>
<p><strong>Constraints:</strong> 2 $\leq$ n $\leq$ 20 </p>
<p><strong>Output Format:</strong></p>
<p>Print <strong>10</strong> lines of output; each line <strong>i</strong> (where 1 \leq i \leq 10) contains the <strong>result</strong> of <strong>n x i</strong> in the form:<br><strong>n x i = result</strong></p>
<p>Sample Input: 2</p>
<p>Sample Output:</p>
<figure class="highlight basic"><table><tr><td class="code"><pre><span class="line"><span class="symbol">2 </span>x <span class="number">1</span> = <span class="number">2</span></span><br><span class="line"><span class="symbol">2 </span>x <span class="number">2</span> = <span class="number">4</span></span><br><span class="line"><span class="symbol">2 </span>x <span class="number">3</span> = <span class="number">6</span></span><br><span class="line"><span class="symbol">2 </span>x <span class="number">4</span> = <span class="number">8</span></span><br><span class="line"><span class="symbol">2 </span>x <span class="number">5</span> = <span class="number">10</span></span><br><span class="line"><span class="symbol">2 </span>x <span class="number">6</span> = <span class="number">12</span></span><br><span class="line"><span class="symbol">2 </span>x <span class="number">7</span> = <span class="number">14</span></span><br><span class="line"><span class="symbol">2 </span>x <span class="number">8</span> = <span class="number">16</span></span><br><span class="line"><span class="symbol">2 </span>x <span class="number">9</span> = <span class="number">18</span></span><br><span class="line"><span class="symbol">2 </span>x <span class="number">10</span> = <span class="number">20</span></span><br></pre></td></tr></table></figure>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">   n = int(input())</span><br><span class="line">   <span class="keyword">for</span> i <span class="keyword">in</span> range (1,11):</span><br><span class="line">       <span class="attribute">result</span>=n*i</span><br><span class="line">       <span class="builtin-name">print</span>(<span class="string">'%s x %s = %s'</span>%(n,i,result))</span><br></pre></td></tr></table></figure>
<p><strong>Note</strong>: The format string expression: <strong>print(‘%s x %s = %s’%(n,i,result))</strong>. Use tuple <strong>(n,i,result)</strong> to pass value into the formatted experession.</p>
]]></content>
      <categories>
        <category>HackerRank</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>HackerRank</tag>
        <tag>30 Days Python</tag>
      </tags>
  </entry>
  <entry>
    <title>HackerRank 50 Python Practice</title>
    <url>/2020/07/01/HackerRank-Python-Practice/</url>
    <content><![CDATA[<h4 id="1-Write-Function"><a href="#1-Write-Function" class="headerlink" title="1. Write Function"></a>1. Write Function</h4><p>We add a Leap Day on February 29, almost every four years. The leap day is an extra, or intercalary day and we add it to the shortest month of the year, February.<br>In the Gregorian calendar three criteria must be taken into account to identify leap years:</p>
<ul>
<li>The year can be evenly divided by 4, is a leap year, unless:<ul>
<li>The year can be evenly divided by 100, it is NOT a leap year, unless:<ul>
<li>The year is also evenly divisible by 400. Then it is a leap year.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>This means that in the Gregorian calendar, the years 2000 and 2400 are leap years, while 1800, 1900, 2100, 2200, 2300 and 2500 are NOT leap years.</p>
<a id="more"></a>

<p><strong>Task:</strong><br>You are given the year, and you have to write a function to check if the year is leap or not.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_leap</span><span class="params">(year)</span>:</span>   </span><br><span class="line">    <span class="keyword">if</span> year%<span class="number">400</span>==<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">elif</span> year%<span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">elif</span> year%<span class="number">4</span>==<span class="number">0</span>: </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span> </span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p><strong>Note:</strong> Pay attention to the order among the if condition statement.</p>
<h4 id="2-List-Comprehensions"><a href="#2-List-Comprehensions" class="headerlink" title="2. List Comprehensions"></a>2. List Comprehensions</h4><p>You are given three integers X,Y  and Z representing the dimensions of a cuboid along with an integer N. You have to print a list of all possible coordinates given by (i,j,k) on a 3D grid where the sum of <strong>i+k+j</strong> is not equal to <strong>N</strong>. Here, **0 $\leq$ i $\leq$ X; 0 $\leq$ j $\leq$ Y; 0 $\leq$ k $\leq$ Z</p>
<p><strong>Sample Input:</strong></p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br></pre></td></tr></table></figure>
<p><strong>Sample Output:</strong></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">[[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]]</span><br></pre></td></tr></table></figure>
<p><strong>Solution:</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    x = int(input())</span><br><span class="line">    y = int(input())</span><br><span class="line">    z = int(input())</span><br><span class="line">    n = int(input())</span><br><span class="line">print([[i,j,k] </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(x+<span class="number">1</span>) </span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(y+<span class="number">1</span>) </span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> range(z+<span class="number">1</span>) </span><br><span class="line"><span class="keyword">if</span> ( ( i + j+k )!=n)])</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>HackerRank</category>
      </categories>
      <tags>
        <tag>Code</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Data Visulization and Analysis</title>
    <url>/2020/06/29/y-First-Data-Visulization/</url>
    <content><![CDATA[<blockquote>
<p>In 2017, I started my first coding practice by using R. Then, I realize that computer language is not rocketscience that I can’t never understand.</p>
</blockquote>
<h3 id="Practice-1"><a href="#Practice-1" class="headerlink" title="Practice 1"></a>Practice 1</h3><h4 id="The-potential-relationship-between-United-States-GDP-and-Some-other-economic-indicators-from-year-1960-to-2015"><a href="#The-potential-relationship-between-United-States-GDP-and-Some-other-economic-indicators-from-year-1960-to-2015" class="headerlink" title="The potential relationship between United States GDP and Some other economic indicators (from year 1960 to 2015)"></a>The potential relationship between United States GDP and Some other economic indicators (from year 1960 to 2015)</h4><p>　The data set pick for first practice is aimed to study the potential relationship between United States GDP and some other economic indicators such as population, exports of goods and service, electric power consumption, unemployment rate and average rate index from year 1960 to 2015. The source of data is from World Bank Open Data ( <em><a href="https://data.worldbank.org" target="_blank" rel="noopener">https://data.worldbank.org</a></em>) and National Average Wage Index (<em><a href="https://www.ssa.gov/oact/cola/AWI.html" target="_blank" rel="noopener">https://www.ssa.gov/oact/cola/AWI.html</a>.</em>)<br>In order to find the relationship, I first need to find out the trend of indicators from 1960 to 2015 and make some logical assumptions in mind.</p>
<a id="more"></a>

<p><strong>Load library needed, read the excel file and rename the columns</strong></p>
<pre><code>library(readxl)
library(ggplot2)
USA_GDP = read_excel(&quot;USA GDP.xlsx&quot;)
names(USA_GDP)
## [1] &quot;Year&quot; &quot;Gdp&quot; &quot;Pop&quot; &quot;Exports&quot; &quot;Electric&quot; &quot;House&quot;
## [7] &quot;Urate&quot; &quot;Wage&quot;</code></pre><p><strong>The Change of indicators from 1960 to 2015</strong></p>
<pre><code>#The change of GDP from 1960 to 2015
ggplot(USA_GDP,aes(Year,Gdp))+geom_line()  </code></pre><p><img src="/images/pasted-16.png" alt="upload successful"></p>
<pre><code>#The change of population from 1960 to 2015
ggplot(USA_GDP,aes(Year,Pop))+geom_line()</code></pre><p><img src="/images/pasted-17.png" alt="upload successful"></p>
<pre><code>#The change of Household final consumption expenditure from 1960 to 2015
ggplot(USA_GDP,aes(Year,House))+geom_line()</code></pre><p><img src="/images/pasted-18.png" alt="upload successful"></p>
<h3 id="Data-Visulization-Project-1"><a href="#Data-Visulization-Project-1" class="headerlink" title="Data Visulization Project 1"></a>Data Visulization Project 1</h3><h4 id="Project-Introduction"><a href="#Project-Introduction" class="headerlink" title="Project Introduction"></a>Project Introduction</h4><p>　We may have noticed that recently the United States has brought up several new policies about US tariffs. Especially, when Donald Trump signed a Presidential<br>Memorandum, the United States has announced levies on up to $60 billion in Chinese goods and would impose stiff tariffs on imports of steel and aluminum to all the countries. However, the United States may plan to give exemption to a broad group of allies which include Canada, Mexico. Since China is also a big steel export country,apparently, this policy in some degree will possible have a big effect on Chinese steel and iron industries. We may assume this policy is aimed to against the influx cheap Chinese metal and goods, which may harm American local industry. If the exemption were successfully applied to other countries, China is going to face more severe situation under this circumstance, and the trade battle between U.S and China can possibly turn into a Trade War. This project will analyze basic American import and export of certain taxed product relates to this policy to make logic prediction of the stakes in this competition from my point of views in certain aspects.</p>
<h4 id="Data-Source"><a href="#Data-Source" class="headerlink" title="Data Source"></a>Data Source</h4><p>　All the data can be find in following data website:</p>
<ul>
<li><p>United States Department of Agricultural Economic Research<br><a href="https://www.ers.usda.gov/topics/crops/soybeans-oil-crops/#otherpublications" target="_blank" rel="noopener">https://www.ers.usda.gov/topics/crops/soybeans-oil-crops/#otherpublications</a></p>
</li>
<li><p>The Soybean Processors Association of India<br><a href="http://www.sopa.org/statistics/world-soybean-production/?search_type=search_by_year&amp;years=2017-2018&amp;starting_year_value=&amp;ending_year_value=&amp;submit=Search" target="_blank" rel="noopener">http://www.sopa.org/statistics/world-soybean-production/?search_type=search_by_year&amp;years=2017-2018&amp;starting_year_value=&amp;ending_year_value=&amp;submit=Search</a></p>
</li>
<li><p>World Integrated Trade Solution<br><a href="https://atlas.media.mit.edu/en/profile/country/usa/" target="_blank" rel="noopener">https://atlas.media.mit.edu/en/profile/country/usa/</a></p>
</li>
<li><p>United States Census<br><a href="https://www.census.gov/foreign-trade/balance/index.html" target="_blank" rel="noopener">https://www.census.gov/foreign-trade/balance/index.html</a></p>
</li>
<li><p>UN Comtrade Database<br><a href="https://comtrade.un.org/data" target="_blank" rel="noopener">https://comtrade.un.org/data</a></p>
</li>
</ul>
<h4 id="Research-Questions"><a href="#Research-Questions" class="headerlink" title="Research Questions"></a>Research Questions</h4><ul>
<li>Which countries that United States import and export the most?</li>
<li>Which categories that United States has the most import and export?</li>
<li>If China levy on some American export products, how this policy is going to affect the United States?</li>
</ul>
<h4 id="Final-Data-Visualization"><a href="#Final-Data-Visualization" class="headerlink" title="Final Data Visualization"></a>Final Data Visualization</h4><p>　R and Excel will be used for data cleaning, and Tableau will be considered as my data visualization tools. Since I am going to compare the categories and volume of import and export, bar graphs, heatmaps and pie chart are good methods to express the data. Therefore, Tableau will be my first choice to visualize my data. The data in this project is quite large and complicate, sometimes I have use R to transform my data to fit the format of Tableau. Of course, Excel will also consider as my data editing tool. Visualization types will be:<br>• Bar graph of Overall import and export value from 2000-2017<br>• Line chart of Trade deficit from 2007-2017<br>• Heatmap of Product categories that United States export and import<br>• Pie Charts of Proportion of World Soybean total production</p>
<h4 id="Data-Analysis"><a href="#Data-Analysis" class="headerlink" title="Data Analysis"></a>Data Analysis</h4><h5 id="U-S-2000-2017-Overall-Import-and-Export-goods-and-service"><a href="#U-S-2000-2017-Overall-Import-and-Export-goods-and-service" class="headerlink" title="U.S 2000 - 2017 Overall Import and Export (goods and service)"></a>U.S 2000 - 2017 Overall Import and Export (goods and service)</h5><p><img src="/images/pasted-23.png" alt="upload successful"><br><img src="/images/pasted-24.png" alt="upload successful"></p>
<ul>
<li>According to the bar graph of U.S overall Import and Export. From 2000 – 2017, the export and import appear rising tendency. But the trade deficit reach the highest in 2006 and reduce to 384 billions dollars then kept fluctuating around 500 billions dollars. In order to reduce the trade deficit, Trump brought up a series of trading policy on export and import.</li>
</ul>
<h5 id="March-2018-The-Value-of-U-S-Export-and-Import-To-Top-15-Countries-goods-only"><a href="#March-2018-The-Value-of-U-S-Export-and-Import-To-Top-15-Countries-goods-only" class="headerlink" title="March 2018, The Value of U.S Export and Import  To Top 15 Countries. (goods only)"></a>March 2018, The Value of U.S Export and Import  To Top 15 Countries. (goods only)</h5><p><img src="/images/pasted-27.png" alt="upload successful"></p>
<p><img src="/.io//images%5Cpasted-28.png" alt="upload successful"></p>
<ul>
<li>By comparing two bar graphs, we can easily see that Canada, Mexico, China are top three countries in the value of American import and export. Canada is the biggest American exportation country. And China is the biggest American importation country. Since America relies on China more than China rely on America, we may logically assume once China start its retaliatory tariffs on US exports, the United State may have more loss than Chinese.</li>
</ul>
<h5 id="Products-that-United-States-Imports-from-China-in-2017"><a href="#Products-that-United-States-Imports-from-China-in-2017" class="headerlink" title="Products that United States Imports from China in 2017"></a>Products that United States Imports from China in 2017</h5><p><img src="/images/pasted-35.png" alt="upload successful"></p>
<ul>
<li>From the heatmap, we can find that the major categories that United States import are cell phones and other household goods, computer and computer accessories, telecommunication equipment and so on… These are major areas on which Donald Trump wants to apply tariffs, in order to slow down or restrict the rising trend of China taking dominant in these areas(high-tech products), and try to take America back into the leading position in these areas.</li>
</ul>
<h5 id="Products-that-United-States-Exports-to-China-in-2017"><a href="#Products-that-United-States-Exports-to-China-in-2017" class="headerlink" title="Products that United States Exports to China in 2017"></a>Products that United States Exports to China in 2017</h5><p><img src="/images/pasted-36.png" alt="upload successful"></p>
<ul>
<li>From the heatmap, we can find that the major categories that United States export to China are civilian aircraft, engines, soybeans, Passenger cars, semi-products. Those categories will be the threatens to United States and have a big chance becoming the target of China as revenge. As far as we know, Chinese government has announced that it will impose 15% tariffs on 128 American made products include fruit, nuts and wine and up to 25% on pork as initially fight back. Furthermore, Chinese government will probably keep imposing tariffs on more products made by United States depend on how the battle goes. </li>
</ul>
<h5 id="Threaten-Tariffs-on-Soybeans"><a href="#Threaten-Tariffs-on-Soybeans" class="headerlink" title="Threaten - Tariffs on Soybeans"></a>Threaten - Tariffs on Soybeans</h5><p><img src="/images/pasted-38.png" alt="upload successful"></p>
<ul>
<li>Obviously, the United State and Brazil are two major soybeans producers as well as exporters in this world. If China imposes tariffs on soybean, which means it gives up one of the largest soybean import resource in the world, I believe that China won’t insist for a long time because there is no other supplier except U.S can provide such tremendous amount of soybeans.  </li>
</ul>
<p><img src="/images/pasted-43.png" alt="upload successful"></p>
<p><img src="/images/pasted-44.png" alt="upload successful"></p>
<ul>
<li><p>By comparing two graphs, it is easy to see the export pattern of two countries.  Most of soybeans in brazil were exported to China in the period from March to September. In rest of the year , China has imported soybeans from the United States, which is the reason I consider that China will keep suffering from the loss until it find a way to solve  domestic demand of soybeans. In a short period, Brazil and Argentina would be the best choice and support for China to pass through the “harsh time”. However, It is hard for China to find suppliers that can really fill China’s soybeans needs for a long term. The structure of global supply chain is not that easy to change.</p>
</li>
<li><p>Moreover, We may consider another situation: Is it possible for Brazil to provide enough soybean to fulfill the demand of China? The answer is No. Maybe there are several ways that can mitigate the reliance on American soybeans such as importing more soybeans from Brazil and Argentina; however, there is no way that China can stay away from the loss. </p>
</li>
</ul>
<h5 id="Threaten-Tariffs-on-Pork-and-Meat-Products"><a href="#Threaten-Tariffs-on-Pork-and-Meat-Products" class="headerlink" title="Threaten - Tariffs on Pork and Meat Products"></a>Threaten - Tariffs on Pork and Meat Products</h5><p><img src="/images/pasted-41.png" alt="upload successful"></p>
<ul>
<li>Broiler and pork are the main meat export product of United States, which take up42.5% and  32.35% of total meat exportation respectively. If China wants to increase the tax on meat product, the United State would have big effect on domestic farmers only if China is the big pork and broiler importer of the United States.</li>
</ul>
<h4 id="Future-Work"><a href="#Future-Work" class="headerlink" title="Future Work"></a>Future Work</h4><ul>
<li><p>The effect of Tariffs between two large countries has always been a complicate issue. The change of tariffs in a large will not only affect domestic supply and demand or domestic price, but also will have big global effect. Taking a simple example in this case, the policy that China imposes tariffs on soybeans will definitely benefit to Brazil, Argentina and all other countries who have ability to provide soybeans. </p>
</li>
<li><p>This project can expend to many areas. Base on the information I concluded, we just need to gather a little bit more of data on globe soybean price to calculate the effect of tariffs on the volume change of Import and export as result. </p>
</li>
<li><p>We can furthermore investigate whether the tariffs on Auto has really harmed the interest of those Giant Auto companies. Because Tariffs is such a complicate topic, we can apply many economic concepts and do the research</p>
</li>
</ul>
<h4 id="Conclusion-and-Prediction"><a href="#Conclusion-and-Prediction" class="headerlink" title="Conclusion and Prediction"></a>Conclusion and Prediction</h4><p>　All the activities between China and the United State are just the “normal”friction in the international trade. I don’t believe that the tension and friction between　these two superpower countries so far will escalate into the real Trade War. And I don’t think they will even allow this happen. We know China and America play vital roles in the global economy, the chain reaction of trade war in global and national economy is going to be destructive; therefore, there is no way for both China and the United State to be involve in a long-term trade battle. China won’t, neither Donald Trump. Overall, people are responsible for countries’ international trade policies. Even though statistics says the effect of certain policy is minor, the loss is on people and people who has business involved. It is simple logic for everyone to understand that collaboration between two countries can lead to win-win situation. Negotiation is<br>the best way to reduce the friction and solve problems, which is what China and America are doing right now. If two countries reach a common agreement, the trade battle will eventually end.</p>
]]></content>
      <categories>
        <category>Project</category>
      </categories>
      <tags>
        <tag>Tableau</tag>
        <tag>Data analysis</tag>
      </tags>
  </entry>
  <entry>
    <title>KPMG Vitrual Internship Notes</title>
    <url>/2020/06/02/posttry-to-keep-my-website-runing/</url>
    <content><![CDATA[<h3 id="Task-1-Identifying-the-data-quality-issues-and-how-this-may-impact-our-analysis-going-forward"><a href="#Task-1-Identifying-the-data-quality-issues-and-how-this-may-impact-our-analysis-going-forward" class="headerlink" title="Task 1: Identifying the data quality issues and how this may impact our analysis going forward?"></a>Task 1: Identifying the data quality issues and how this may impact our analysis going forward?</h3><p>Since the company didn’t define its own business definition for data quality evaluation, I will follow the general process.(This task is intentionally solved by Python)</p>
<p>To evaluate the quality of data, we can follow the Six Standard Data Quality Dimension: </p>
<a id="more"></a>

<ul>
<li><strong>Accuracy</strong>: The degree to which the data correctly describe the ‘real-world’ objects. <strong>Example:</strong> <em>if a man is 30 years old, but the data is 35 years old.</em></li>
<li><strong>Completeness</strong>: Whether the data fulfill the expectation of business comprehensiveness; in other words, whether you can extract the information you want from the data.</li>
<li><strong>Uniqueness</strong>: Make sure there is no duplicate record in the dataset. <strong>Example</strong>: <em>There are 300 students in total, but there are 350 records</em></li>
<li><strong>Timeliness</strong>：Make sure that the data is recorded at the time when it occurred. No delay.</li>
<li><strong>Validity</strong>：Data are valid if it conforms to the syntax (format, type, range) of its definition.**</li>
<li><strong>Consistency</strong>：The data should be the same as input in other columns.<strong>Example</strong>: <em>If a student name:’Peter Pan’ is in the class name-list, then ‘Peter Pan’in the school name-list should be the same as class name-list.</em> </li>
</ul>
<p><a href="https://www.whitepapers.em360tech.com/wp-content/files_mf/1407250286DAMAUKDQDimensionsWhitePaperR37.pdf" target="_blank" rel="noopener">Reference: Defining Data Quality Dimensions</a></p>
<h4 id="Task-1-Problems-and-Notes"><a href="#Task-1-Problems-and-Notes" class="headerlink" title="Task 1 Problems and Notes"></a>Task 1 Problems and Notes</h4><ol>
<li>How to use python read the sheets in Excel files ?</li>
</ol>
]]></content>
      <categories>
        <category>Project Notes</category>
      </categories>
      <tags>
        <tag>Vitrual Internship</tag>
      </tags>
  </entry>
  <entry>
    <title>Statistical Learning(Rstudio)3-4</title>
    <url>/2020/07/03/tro-to-Statistical-Learning-Rstudio/</url>
    <content><![CDATA[<h3 id="Practice-3-Regression-Tree-Cross-Validation-Mallow-CP-BIC"><a href="#Practice-3-Regression-Tree-Cross-Validation-Mallow-CP-BIC" class="headerlink" title="Practice 3 - Regression Tree, Cross-Validation,Mallow CP, BIC"></a>Practice 3 - Regression Tree, Cross-Validation,Mallow CP, BIC</h3>

	<div class="row">
    <embed src="\me\H3.pdf" width="100%" height="550" type="application/pdf">
	</div>




<h3 id="Practice-4-SVM-Regressions"><a href="#Practice-4-SVM-Regressions" class="headerlink" title="Practice 4 - SVM, Regressions"></a>Practice 4 - SVM, Regressions</h3>

	<div class="row">
    <embed src="\me\H4.pdf" width="100%" height="550" type="application/pdf">
	</div>


]]></content>
  </entry>
  <entry>
    <title>Web-Mining Full Project Report</title>
    <url>/2020/06/26/web-Mining-Full-Project-Report/</url>
    <content><![CDATA[<blockquote>
<p>In retrospect my first NLP project,it was a really great learning experience that got me through the process of nature language processing, and piqued my interest to the Data Science.</p>
</blockquote>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>　In the past one year, PUBG became one of the most popular games in the word and at the same time it also received thousands of negative comments and thus I planned to start a project to help those developers and operators extract valuable information from those critics. The purpose of my project is to get suggestions from those critics, and then I plan to assign labels for players manually to classify those clear-minded supporters and critics and then train some classification models to discover more critics with firm stand.Finally, I will propose some future improvements for this project which I could have done better and also as reference for my next project.</p>
<a id="more"></a>

<h3 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h3><p>　PUBG, one of the most popular shooting games on steam, was published by PUBG Corporation, a subsidiary of South Korean video game company Bluehole. This game was released officially in September 2018. The game is one of the best-selling of all time, with over fifty million sold across all platforms by June 2018. In addition, the Windows version holds a peak concurrent player count of over three million on Steam, which is an all-time high on the platform. PUBG received thousands of reviews from players, who found that there are still many bugs and problems existed in the game.Thus, I decide to research on discovering useful information from those reviews.</p>
<h3 id="Purpose"><a href="#Purpose" class="headerlink" title="Purpose"></a>Purpose</h3><p>　In this project, I am trying to detect some useful information from the reviews and have a deep understanding of the game by analysis crawled from the Steam reviews community. After this project, I hope my analysis will help game developers identify the problems that most players concerned about.</p>
<h3 id="Data-Preparation"><a href="#Data-Preparation" class="headerlink" title="Data Preparation"></a>Data Preparation</h3><p>　In this project, the data source comes from Steam.I use <strong>Selenium</strong> to scrape some reviews page.I use CSS selectors to get all the attributes including user comment date, user reviews, whether users recommend or not, how many hours spent on the game, and how many games users hold in the account.</p>
<h3 id="Data-Description"><a href="#Data-Description" class="headerlink" title="Data Description"></a>Data Description</h3><p>　The data size is 2070. The data contains three independent variables including spent hours, hold products and user reviews, and one dependent variable which is “recommended or not”. Spent hours refers to how many hours that players have spent on the game. Hold products refers to how many games user hold in their accounts. User reviews refer to what players comment on the website. Recommend or not refers to whether the player recommends this game or not. The sample data presented below:<br><img src="/images/pasted-1.png" alt="upload successful"></p>
<p>　On the platform, each user can easily write down their feedbacks toward the game and they will assign a label of whether they want to recommend or not-recommend this game to other players. Steam will also list the information of users such as hours of playing, the Steam products in the user’s account, and other players’ attitudes toward this comment. This review system will give the game companies or developers an overall insight into how this running on this platform by collecting all the data from users’ reviews. The user interface shows below:<br> <img src="/images/pasted-2.png" alt="upload successful"></p>
<h3 id="Data-cleaning"><a href="#Data-cleaning" class="headerlink" title="Data cleaning"></a>Data cleaning</h3><p>　The data contains some symbols and stop words which cause problems for me to find meaningful information from the user reviews and thus I remove these noise and transfer all characters into lower cases and split the reviews into words.</p>
<h3 id="Exploratory-Data-Analysis"><a href="#Exploratory-Data-Analysis" class="headerlink" title="Exploratory Data Analysis"></a>Exploratory Data Analysis</h3><p>　Next, I did some simple exploratory data analysis to find the correlation among these variables. Firstly, I made a bar chart to present the relation between spent hours  and recommendations<br> <img src="/images/pasted-3.png" alt="upload successful"><br>As the bar chart presents above, I find that the people who have spent more than 1900 hours on PUBG tend to recommend this game. In other words, this game is very popular with old players, and thus the reviews made by this part of players are more meaningful for the operator.<br>And then, I made a scatter plot to explore the relation between spent hours and hold products.</p>
<p><img src="/images/pasted-6.png" alt="upload successful"></p>
<h3 id="Modeling"><a href="#Modeling" class="headerlink" title="Modeling"></a>Modeling</h3><p>　In this part, I use both supervised learning algorithms and unsupervised learning algorithms to make models.</p>
<h4 id="Unsupervised-learning"><a href="#Unsupervised-learning" class="headerlink" title="Unsupervised learning"></a>Unsupervised learning</h4><h5 id="VADER"><a href="#VADER" class="headerlink" title="VADER"></a>VADER</h5><p>　<strong>VADER</strong> analyzes a piece of text to see if any of the words in the text is present in the lexicon. Sentiment metrics are derived from the ratings of such words positive, neutral, and negative, represent the proportion of the text that falls into those categories.The final metric, the compound score, is the sum of all the lexicon ratings which have been standardized to range between -1 and 1 based on some heuristics.In my project, I want to see users’ sentiment for each of the reviews by applying VADER analysis, and group those negative sentiment reviews for company inspect.</p>
<p><img src="/images/pasted-7.png" alt="upload successful"></p>
<p>　From the result shown above, reviews have been classified into three categories: positive sentiment, neutral sentiment, and negative sentiment.In positive sentiment,77.45% of reviews have been correctly　classified;In neutral sentiment,75.33 are recommended reviews and 24.66% are not recommended reviews; In negative sentiment, 26.38% negative reviews　have been correctly classified.I visualize the model result.The model has bad performance on negative sentiment. And then I try to find the reasons.After I dig into the reviews, I find out the reviews sometimes full of sarcasm, the computer is not capable of recognizing the emotion behind the sentences. For example: “This game used to be good, but now it is just game for cheaters.” Then I got a conclusion that the labels in the review system didn’t truly reflect the attitudes of players and the game developer can also possibly mislead by the data of labels.</p>
<h5 id="LDA"><a href="#LDA" class="headerlink" title="LDA"></a>LDA</h5><p>　Due to the massive information of reviews, it’s difficult for operators to analyze the reviews one by one. So, I use LDA (Latent Dirichlet allocation) to generate topics for the document. This model reduces the dimensionalities of words and thus it worked more efficiently compared with bag-of-words model and got rid of overfitting. I visualized three top topics as below:</p>
<p><img src="/images/pasted-9.png" alt="upload successful"><br>　Through these pictures, I found more negative words than positive words. These words state that the server of the game is bad and mountains of cheaters in this game and this game didn’t make any improvement over time. This result may confuse us why there are more negative words about this game, and in the EDA stage I found more people recommended this game.In the VADER model, I have found that 75.33% of people who have neutral attitudes have been classified as supporters. And by reading some comments, I found that these people’s comments contain a lot of negative words and that’s the reason why I found so many negative words here. Through the LDA and VADER model, I got a conclusion that I cannot simply classify people by their comments’ labels, and thus, I planned to select those clear-minded comments to train the classification model to find more players with a firm stand.</p>
<h4 id="Supervised-learning"><a href="#Supervised-learning" class="headerlink" title="Supervised learning"></a>Supervised learning</h4><p>　The classification models are applied to detect positive and negative users. Since there are a great many reviews are not labeled in other sources. It is necessary to classify a large number of reviews and get directions for later improvement, especially from the negative sentiments.</p>
<h5 id="Multinomial-Naive-Bayes"><a href="#Multinomial-Naive-Bayes" class="headerlink" title="Multinomial Naïve Bayes"></a>Multinomial Naïve Bayes</h5><p>　<strong>Multinomial Naïve Bayes</strong> is suitable for classification with word counts for text classification, such as TF-IDF weight.<br>As the result shows above, this model has a good performance. The precision rate is 0.84 and the recall rate is 0.82.<br><img src="/images/pasted-11.png" alt="upload successful"></p>
<h5 id="Support-Vector-Classification"><a href="#Support-Vector-Classification" class="headerlink" title="Support Vector Classification"></a>Support Vector Classification</h5><p>　<strong>Support vector machine</strong> constructs a hyper-plane or set of hyper-planes in a high or infinite-dimensional space, which can be used for classification. As the pictures are shown above, a good separation is achieved by the hyper-plane that has the largest distance to the nearest training data points of any class. It has 0.85 of precision rate and 0.83 of recall rate.</p>
<p><img src="/images/pasted-12.png" alt="upload successful"></p>
<h5 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a><strong>Logistic Regression</strong></h5><p>　<strong>Logistic Regression</strong> model the probabilities of a recommendation as a linear function of documents term matrix and classify reviews into two categories based on TF-IDF weights of bag-of-words.<br>As the pictures are shown above, it has 84% precision rate and 80% recall rate. In summary, MNB, SVM, and Logistic Regression have good performance.</p>
<p><img src="/images/pasted-13.png" alt="upload successful"></p>
<h5 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a><strong>CNN</strong></h5><p>　<strong>CNN</strong> model is introduced since it has advantages in imbalanced data classification. The doc2vec and word2vec are used to train a large number of unlabeled reviews to generate a fixed weights word matrix to map the word in the embedding phase. The doc2vec is different in predicting the word by concatenating the paragraph vector D (shared within the paragraph). The words vector trained by Doc2Vec has a better performance when checking the similarities of the words.<br>The figure describes the top 5 most similar word with ‘play’:</p>
<p><img src="/images/pasted-14.png" alt="upload successful"><br>The CNN model is using three sizes of filters (bigram, trigram, and quadrigram), each size has 64 filters in the convolutional layer.</p>
<p><img src="/.io//images%5Cpasted-15.png" alt="upload successful"><br>In summary, the CNN model that using a pre-trained matrix has a better performance as the picture shown above.</p>
<h3 id="Word-Interpretation"><a href="#Word-Interpretation" class="headerlink" title="Word Interpretation"></a>Word Interpretation</h3><p>　To get some insights from negative sentiment reviews, I use TFIDF weights and Word2Vec to dig out content from reviews.<br>As the picture shows, I picked the top ten words which have the highest frequency. Some words such as bad, time, money are keywords that might point to the potential problem.<br>Next step, I use Word2Vec to find the most similar words with these top 10 words, trying to find correlations between targeted words.<br>As a result, the problems found are as follows:</p>
<ol>
<li>A lot of game issues</li>
<li>Serious time delay for server lags</li>
<li>Devs(Developer) fix the bug</li>
<li>Vehicle issue in the game</li>
<li>Waste money</li>
<li>A lot of cheaters</li>
</ol>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>　In unsupervised learning, I found that the label in the dataset cannot accurately describe the attitude of players, but the purpose of my project is to excavate valuable information from critics and thus it’s very important to train a model to find those critics with frim stand. And then I trained several classification models including Multinomial Naïve Bayes, SVM, Logistic Regression, and CNN, and found that CNN has the best performance among these models. Finally, I explain the words meaning after classification and then give the suggestion based on what I got from the result and raise the suggestion to the company. Wipe out cheaters from the game, it hugely impacts the user’s game experience. Give more support to users when they meet with game issues. Developers need to put more effort to optimize game and fix those existed bugs. Cautiously deal with the micro-transaction, make it reasonable to users.</p>
<h3 id="Future-Improvement"><a href="#Future-Improvement" class="headerlink" title="Future Improvement"></a>Future Improvement</h3><p>　There are still some improvements that I can make in the future. For example, I can try the Steam Game Platform API,and I can improve VADER by updating the word list. Since VADER is defined as Sentiment metrics techniques, I expect to improve model performance by updating the word list and re-training the model.</p>
]]></content>
      <categories>
        <category>Project</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>NLP</tag>
        <tag>Web Scraping</tag>
      </tags>
  </entry>
  <entry>
    <title>Leetcode Problem Set</title>
    <url>/2020/07/02/Leetcode-Problem-Set/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>Code</tag>
        <tag>Python</tag>
      </tags>
  </entry>
</search>
